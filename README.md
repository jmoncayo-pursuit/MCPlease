# MCPlease MVP - Offline AI Coding Assistant

ğŸ¤– **Powered by gpt-oss-20b** | ğŸ”’ **100% Offline & Private** | ğŸ’» **Optimized for Mac** | âš¡ **Zero-configuration setup**

MCPlease MVP is an offline AI coding assistant that runs entirely on your Mac. It provides intelligent code completion, explanations, and debugging help using a locally-hosted 21.5B parameter language model, ensuring your code never leaves your machine.

## âœ¨ Features

- **ğŸ”’ Complete Privacy**: All AI processing happens locally - your code never leaves your machine
- **âš¡ Zero Setup**: One command installation with automatic configuration
- **ğŸ§  Powerful AI**: Uses gpt-oss-20b (21.5B parameters) for high-quality code assistance
- **ğŸ’» Mac Optimized**: Intelligent memory management works great on 16GB+ Mac systems
- **ğŸ”Œ VSCode Ready**: Seamless integration with Continue.dev extension
- **ğŸš€ Fast Inference**: Optimized with vLLM and MXFP4 quantization

## ğŸš€ Quick Start

### One-Command Installation (Recommended)

```bash
curl -sSL https://raw.githubusercontent.com/your-org/mcplease-mvp/main/install.sh | bash
```

That's it! The installer will:
- âœ… Check system requirements
- âœ… Install dependencies
- âœ… Download the AI model
- âœ… Set up everything automatically

### Start Using MCPlease

After installation, restart your terminal and run:

```bash
mcplease --start
```

Or check system status:

```bash
mcplease --status
```

## ğŸ“‹ System Requirements

- **macOS** (Apple Silicon or Intel)
- **16GB+ RAM** (12GB minimum, 32GB+ ideal)
- **Python 3.9-3.12**
- **50GB+ free disk space** (for model storage)
- **Internet connection** (for initial setup only)

## ğŸ”Œ VSCode Integration

1. **Install Continue.dev extension** in VSCode
2. **Configure the extension** to use MCPlease:
   - Open Continue.dev settings
   - Add MCPlease as a provider
   - Set endpoint to your local server
3. **Start coding** with AI assistance!

## ğŸ’¡ Usage Examples

### Code Completion
```python
def fibonacci(n):
    # AI will complete this function
```

### Code Explanation
Select any code and ask: "What does this function do?"

### Debugging Help
Paste error messages and get intelligent debugging suggestions.

## ğŸ› ï¸ Manual Installation

If you prefer manual setup:

```bash
# Clone repository
git clone https://github.com/your-org/mcplease-mvp.git
cd mcplease-mvp

# Run setup
python mcplease.py --setup

# Start server
python mcplease.py --start
```

## ğŸ“Š Performance

- **Response Time**: ~2-5 seconds for code completion
- **Memory Usage**: 8-12GB during inference
- **Model Size**: ~21GB on disk (compressed)
- **Context Length**: Up to 8192 tokens

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VSCode IDE    â”‚â—„â”€â”€â–ºâ”‚  MCP Protocol    â”‚â—„â”€â”€â–ºâ”‚  AI Model       â”‚
â”‚  (Continue.dev) â”‚    â”‚     Server       â”‚    â”‚  (gpt-oss-20b)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Memory Manager   â”‚
                       â”‚ & Optimization   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Advanced Usage

### Custom Memory Limits
```bash
mcplease --start --max-memory 8  # Use max 8GB RAM
```

### Debug Mode
```bash
mcplease --start --debug  # Enable detailed logging
```

### Custom Model Path
```bash
mcplease --start --model-path /path/to/model
```

## ğŸ§ª Development

### Project Structure
```
mcplease-mvp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/        # AI model management
â”‚   â”œâ”€â”€ mcp/           # MCP protocol implementation  
â”‚   â”œâ”€â”€ environment/   # Environment setup
â”‚   â””â”€â”€ utils/         # Shared utilities
â”œâ”€â”€ tests/             # Test suite
â”œâ”€â”€ examples/          # Usage examples
â””â”€â”€ mcplease.py        # Main entry point
```

### Running Tests
```bash
python -m pytest tests/ -v
```

### Memory Management Demo
```bash
python examples/memory_management_demo.py
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Make your changes and add tests
4. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Documentation**: Check our [docs](docs/) folder
- **Issues**: Report bugs on [GitHub Issues](https://github.com/your-org/mcplease-mvp/issues)
- **Discussions**: Join our [GitHub Discussions](https://github.com/your-org/mcplease-mvp/discussions)

## ğŸ™ Acknowledgments

- **OpenAI** for the gpt-oss-20b model
- **vLLM team** for the high-performance inference engine
- **Continue.dev** for the excellent VSCode integration
- **Hugging Face** for model hosting and distribution

---

**Made with â¤ï¸ for developers who value privacy and performance**